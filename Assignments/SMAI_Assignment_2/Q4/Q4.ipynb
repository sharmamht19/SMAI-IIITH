{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500e9f2c-75d3-4865-aaa4-f45e1642d29a",
   "metadata": {},
   "source": [
    "# SMAI Assignment - 2\n",
    "\n",
    "## Question - `4` : Gaussian Naïve Bayes\n",
    "\n",
    "| | |\n",
    "|- | -|\n",
    "| Course | Statistical Methods in AI |\n",
    "| Release Date | `16.02.2023` |\n",
    "| Due Date | `24.02.2023` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086e75e8-62ac-4f03-8ff3-936f60dbb0be",
   "metadata": {},
   "source": [
    "This question will have you working and experimenting with the Gaussian Naïve Bayes classifier. Initially, you will calculate the priors and the parameters for the Gaussians. Then, you will use the likelihoods to classify the test data. Please note that use of `sklearn` implementations is only for the final question in the Experiments section.\n",
    "\n",
    "The dataset is simple and interesting, the [Wireless Indoor Localization Data Set](https://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization). An office has seven Wi-Fi routers and its signal strengths received from these routers categorize the location of the receiver (in one of four rooms). There are 7 attributes and a class label column that can take 4 values. The data is present in `wifiLocalization.txt`. It contains 2000 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5034071d-eda2-401d-95f2-1957acb0d85c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123c3de5-95b1-47c3-a3e6-0efc4b5c9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# additional imports if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb53a58-bb13-472c-be7e-af487a8128a6",
   "metadata": {},
   "source": [
    "### Estimate Gaussian parameters\n",
    "\n",
    "Write a function to estimate the parameters of the Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77ba7db2-d539-4a5a-80d5-aaf3afb51996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c230b-1a48-40e2-987d-5c423c091ca4",
   "metadata": {},
   "source": [
    "### Calculate priors\n",
    "\n",
    "Write a function to calculate the priors for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a8178d8-4cfe-410c-a1a5-7e89b406f5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70aa354-8c95-45b5-a94e-fbd74db1d58e",
   "metadata": {},
   "source": [
    "### Likelihood + Classification\n",
    "\n",
    "Given a test sample, write a function to get the likelihoods for each class in the sample. Use the Gaussian parameters and priors calculated above. Then compute the likelihood that the sample belongs to each class and return the class with the highest likelihood.\n",
    "\n",
    "What is a common problem with the likelihoods? How can you fix it? Redo the classification with the fixed likelihoods. (You can either write another function or modify the existing one after mentioning the reason for the change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ae21c1c-1cb3-4379-88cc-fb032ce3b2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae1dd54-f718-424c-81ef-ba3a25dd09ef",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "The data has been loaded onto a Pandas DataFrame. Try to get an initial feel for the data by using functions like `describe()`, `info()`, or maybe try to plot the data to check for any patterns.\n",
    "\n",
    "Note: To obtain the data from the UCI website, `wget` can be used followed by shuffling the samples using `shuf` and adding a header for easier reading via `pandas`. It is not necessary to view the data in a DataFrame and can be directly loaded onto NumPy as convenient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e64cdf6e-dc06-45f1-b770-8b8e61f267eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('wifiLocalization.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3a0a3dd-cb25-426d-bfed-d0c075aea95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708f659-b930-4219-b8d4-46fffc843fb0",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "\n",
    "It is a good practice to split the data into training and test sets. This is to ensure that the model is not overfitting to the training data. The test set is used to evaluate the performance of the model on unseen data. The test set is not used to train the model in any way. The test set is only used to evaluate the performance of the model. You may use the `train_test_split` function from `sklearn.model_selection` to split the data into training and test sets.\n",
    "\n",
    "It is a good idea to move your data to NumPy arrays now as it will make computing easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527e95e0-cf05-467a-9144-36664968277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e4e40-8ef7-4958-a6c3-2bd606c716fc",
   "metadata": {},
   "source": [
    "### Experiments\n",
    "\n",
    "1. Estimate your model on the training data.\n",
    "2. Plot the Gaussian probability density functions for each class after estimation.\n",
    "3. Classify the test data using your model.\n",
    "4. Pick a few samples from the test set that were misclassified and plot them along with the Gaussian probability density functions for each class. What do you observe?\n",
    "5. Find if there are any features that are redundant. If so, remove them and repeat the experiments. How does the performance change?\n",
    "6. Conversely, are there certain features that overpower the likelihood scores independently? Test this hypothesis empirically by only using hat/those feature(s) and repeating the experiments. How does the performance change?\n",
    "7. Compare your results with the `scikit-learn` implementation. You can use the `GaussianNB` class from `sklearn.naive_bayes`. You can use the `score` function to get the accuracy of the model on the test set.\n",
    "8. (Optional) Try other Naïve Bayes classifiers from [`sklearn.naive_bayes`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.naive_bayes) and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98c17baa-7cba-4a85-867b-96778eb9dcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
